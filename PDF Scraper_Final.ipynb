{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfFileReader('C:/Users/Nigel/Downloads/article1.pdf')\n",
    " \n",
    "# printing number of pages in pdf file\n",
    "reader.getNumPages()\n",
    " \n",
    "# getting a specific page from the pdf file\n",
    "page = reader.pages[0]\n",
    "# extracting text from page\n",
    "#text = reader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfFileReader('C:/Users/Nigel/Downloads/article1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProcessor(reader):\n",
    "    processedText=\"\"\n",
    "    for pageNo in range(reader.getNumPages()):\n",
    "        page = reader.pages[pageNo]\n",
    "        info = page.extractText()\n",
    "        if(info.find(\"This article is licensed under\")!=-1):\n",
    "            continue\n",
    "        info = info.rstrip(\"\\n\")\n",
    "        char = 0;\n",
    "        while char < len(info):\n",
    "            #clean up the text to be used for summary\n",
    "            if(char!=len(info)-1 and info[char:char+2]==\"\\n\"):\n",
    "                processedText+=(\" \")\n",
    "                char+=2\n",
    "            elif(info[char:char+2]==\"  \"):\n",
    "                processedText+=(\"\")\n",
    "            elif(info[char]==\"˚\" and info[char+1]!=\" \"):\n",
    "                processedText+=(\"Th\")\n",
    "            elif(info[char]==\"˝\"):\n",
    "                processedText+=\"f\"\n",
    "            elif(info[char]==\"˜\" and info[char-1].isalpha()):\n",
    "                processedText+=\"ff\"\n",
    "            elif(info[char]==\"-\"):\n",
    "                char+=2\n",
    "            elif(info[char]==\" \" and info[char-1].isnumeric()):\n",
    "                processedText+=(\"\")\n",
    "            else:\n",
    "                processedText+=info[char]\n",
    "            char+=1\n",
    "    #return furnished and cleaned text\n",
    "    return processedText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "on is 7% [\n",
      "2]. Diabetes is a leading cause of mortality in \n",
      "Accra, the capital of Ghana. [\n",
      "3] However, people living \n",
      "with diabetes (PLD) often have limited knowledge about \n",
      "selfnagement. [\n",
      "4] This could contribute to poor gly\n",
      "emic control.\n",
      "Selfre is essential for PLD. This underpins the need \n",
      "for selfnagement education. In highcome coun\n",
      "ies, structured diabetes selfnagement education \n",
      "(DSME) pro\n"
     ]
    }
   ],
   "source": [
    "print(textProcessor(reader)[1500:1900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedText=textProcessor(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "data = []\n",
    "df = pd.DataFrame(data, columns=['BERT'])\n",
    "list2=[]\n",
    "j=0\n",
    "for i in range(0,len(processedText),512):\n",
    "    k=j+511\n",
    "    while k>0:\n",
    "        if(processedText[k]==\".\"):\n",
    "            break\n",
    "        else:\n",
    "            k-=1\n",
    "    para1uncut=processedText[j:k]\n",
    "    if(len(para1uncut)<5):\n",
    "        j=k\n",
    "    else:\n",
    "        list2.append(processedText[j:k])\n",
    "        j=k\n",
    "df['BERT']=list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lampteyff\\netffal. BMC Health Services Researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. The images or \\nother third party material i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. The Creative Commons Public Domain Dedicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\nOpen Access\\nBMC Health Services ResearchCh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>. Grobbee\\n3, George\\n Obeng Adjei\\n16,17and K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>.\\nOur inability to standardise usual care bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>. This difference could also have biased \\nour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>. This design increases the internal validity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>. We excluded participants \\nwho were not ambu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>. \\n30Deprivation as commonly pertains \\nin re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BERT\n",
       "0   Lampteyff\\netffal. BMC Health Services Researc...\n",
       "1   . The images or \\nother third party material i...\n",
       "2   . The Creative Commons Public Domain Dedicatio...\n",
       "3   .\\nOpen Access\\nBMC Health Services ResearchCh...\n",
       "4   . Grobbee\\n3, George\\n Obeng Adjei\\n16,17and K...\n",
       "..                                                ...\n",
       "59  .\\nOur inability to standardise usual care bet...\n",
       "60  . This difference could also have biased \\nour...\n",
       "61  . This design increases the internal validity ...\n",
       "62  . We excluded participants \\nwho were not ambu...\n",
       "63  . \\n30Deprivation as commonly pertains \\nin re...\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lampteyff\n",
      "etffal. BMC Health Services Research (2023) 23:199 \n",
      "https://doi.org/10.1186/s129133188RESEARCH\n",
      "© The Author(s) 2023. \n",
      "Open Access\n",
      " This article is licensed under a Creative Commons Attribution 4.0International License, which \n",
      "permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \n",
      "original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made\n",
      "________________________________________________Next Paragraph______________________________\n",
      ". The images or \n",
      "other third party material in this article are included in the article™s Creative Commons licence, unless indicated otherwise in a credit line \n",
      "to the material. If material is not included in the article™s Creative Commons licence and your intended use is not permitted by statutory \n",
      "regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \n",
      "licence, visit \n",
      "http:// creat\n",
      " iveco\n",
      " mmons.\n",
      " org/\n",
      " licen ses/ by/4.\n",
      " 0/\n",
      "________________________________________________Next Paragraph______________________________\n",
      ". The Creative Commons Public Domain Dedication waiver (\n",
      "http:// creat\n",
      " iveco\n",
      " mmons.\n",
      " org/\n",
      " publi cdoma in/ zero/1.\n",
      " 0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data\n",
      "________________________________________________Next Paragraph______________________________\n",
      ".\n",
      "Open Access\n",
      "BMC Health Services ResearchChange inffglycaemic control withffstructured \n",
      "diabetes self\n",
      "nagement education inffurban \n",
      "low\n",
      "source settings: multicentre randomised \n",
      "trial offfeThectiveness\n",
      "Roberta\n",
      " Lamptey\n",
      "1,2,3,19*, Mary\n",
      " Amoakohleman\n",
      "3,4, Mary\n",
      " Moffett\n",
      " Barker\n",
      "5,6, Samuel Iddi7, Michelle\n",
      " Hadjiconstantinou5,6, Melanie\n",
      " Davies\n",
      "5,6,8,9, Daniel Darko\n",
      "10,11, Irene\n",
      " Agyepong\n",
      "12, Franklyn\n",
      " Acheampong\n",
      "13, Mary\n",
      " Commey\n",
      "14, Alfred\n",
      " Yawson\n",
      "2,15, Diederick\n",
      " E\n",
      "________________________________________________Next Paragraph______________________________\n",
      ". Grobbee\n",
      "3, George\n",
      " Obeng Adjei\n",
      "16,17and Kerstin\n",
      " Klipsteinobusch\n",
      "3,18Abstract\n",
      " Background\n",
      " In high\n",
      "source settings, structured diabetes self\n",
      "nagement education is associated with improved \n",
      "outcomes but the evidence from low\n",
      "source settings is limited and inconclusive.\n",
      "Aim\n",
      " To compare, structured diabetes self\n",
      "nagement education to usual care, in adults with type 2diabetes, in \n",
      "low\n",
      "source settings.\n",
      "Research design and methods.\n",
      "Design\n",
      " Singleind randomised parallel comparator controlled multi\n",
      "ntre trial\n",
      "________________________________________________Next Paragraph______________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(df['BERT'][i])\n",
    "    #print(\"____________________________________________________Header______________________________\")\n",
    "    #print(df['Paragraph'][i])\n",
    "    print(\"________________________________________________Next Paragraph______________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk==3.5 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from nltk==3.5) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from nltk==3.5) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from nltk==3.5) (2020.10.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from nltk==3.5) (4.50.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk==3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\nigel\\anaconda3\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: requests in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\nigel\\anaconda3\\lib\\site-packages (1.13.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\nigel\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version                                               data\n",
       "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
       "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
       "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
       "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
       "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')\n",
    "coqa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del coqa[\"version\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required columns in our dataframe\n",
    "cols = [\"text\",\"question\",\"answer\"]\n",
    "#list of lists to create our dataframe\n",
    "comp_list = []\n",
    "for index, row in coqa.iterrows():\n",
    "    for i in range(len(row[\"data\"][\"questions\"])):\n",
    "        temp_list = []\n",
    "        temp_list.append(row[\"data\"][\"story\"])\n",
    "        temp_list.append(row[\"data\"][\"questions\"][i][\"input_text\"])\n",
    "        temp_list.append(row[\"data\"][\"answers\"][i][\"input_text\"])\n",
    "        comp_list.append(temp_list)\n",
    "new_df = pd.DataFrame(comp_list, columns=cols) \n",
    "#saving the dataframe to csv file for further loading\n",
    "new_df.to_csv(\"CoQA_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CoQA_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Lampteyff\\netffal. BMC Health Services Researc...\n",
       "1     . The images or \\nother third party material i...\n",
       "2     . The Creative Commons Public Domain Dedicatio...\n",
       "3     .\\nOpen Access\\nBMC Health Services ResearchCh...\n",
       "4     . Grobbee\\n3, George\\n Obeng Adjei\\n16,17and K...\n",
       "                            ...                        \n",
       "59    .\\nOur inability to standardise usual care bet...\n",
       "60    . This difference could also have biased \\nour...\n",
       "61    . This design increases the internal validity ...\n",
       "62    . We excluded participants \\nwho were not ambu...\n",
       "63    . \\n30Deprivation as commonly pertains \\nin re...\n",
       "Name: BERT, Length: 64, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=df[\"BERT\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.gov identiTher:NCT04780425, retrospectively registered on 03/03/2021.\\nResults\\n Recruitment: \\n 22nd until 29th January 2021.\\nWe randomised 206participants (69% female, median age 58\\n years [IQR: 49Œ64], baseline HbA1c median 64\\n mmol/mol [IQR: 45Œ88mmol/mol],7.9%[IQR: 6.4Œ10.2]). Primary outcome data was available for 79and 80participants in \\nthe intervention and control groups, respectively. Reasons for loss to follow\\n were death (n\\n ˜ 1), stroke(n\\n ˜ 1) and \\nunreachable or unavailable (n\\n ˜ 47)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qntext_func():\n",
    "    for i in range(len(df)):\n",
    "        text=df['BERT'][i]\n",
    "        print(text)\n",
    "        question=input(\"Please input the question: \")\n",
    "        input_ids = tokenizer.encode(question, text)\n",
    "        print(\"The input has a total of {} tokens.\".format(len(input_ids)))\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "        #first occurence of [SEP] token\n",
    "        sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "        print(\"SEP token index: \", sep_idx)\n",
    "        #number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\n",
    "        num_seg_a = sep_idx+1\n",
    "        print(\"Number of tokens in segment A: \", num_seg_a)\n",
    "        #number of tokens in segment B (text)\n",
    "        num_seg_b = len(input_ids) - num_seg_a\n",
    "        print(\"Number of tokens in segment B: \", num_seg_b)\n",
    "        #creating the segment ids\n",
    "        segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "        #making sure that every input token has a segment id\n",
    "        assert len(segment_ids) == len(input_ids)\n",
    "        #token input_ids to represent the input and token segment_ids to differentiate our segments - question and text\n",
    "        output = model(torch.tensor([input_ids]),  token_type_ids=torch.tensor([segment_ids]))\n",
    "        #tokens with highest start and end scores\n",
    "        answer_start = torch.argmax(output.start_logits)\n",
    "        answer_end = torch.argmax(output.end_logits)\n",
    "        if answer_end >= answer_start:\n",
    "            answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "        else:\n",
    "            answer = \"I am unable to find the answer to this question. Can you please ask another question?\"\n",
    "\n",
    "        print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "        print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lampteyff\n",
      "etffal. BMC Health Services Research (2023) 23:199 \n",
      "https://doi.org/10.1186/s129133188RESEARCH\n",
      "© The Author(s) 2023. \n",
      "Open Access\n",
      " This article is licensed under a Creative Commons Attribution 4.0International License, which \n",
      "permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \n",
      "original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made\n",
      "Please input the question: none\n",
      "The input has a total of 128 tokens.\n",
      "SEP token index:  2\n",
      "Number of tokens in segment A:  3\n",
      "Number of tokens in segment B:  125\n",
      "\n",
      "Question:\n",
      "None\n",
      "\n",
      "Answer:\n",
      "I am unable to find the answer to this question. can you please ask another question?.\n",
      "\n",
      "\n",
      ". The images or \n",
      "other third party material in this article are included in the article™s Creative Commons licence, unless indicated otherwise in a credit line \n",
      "to the material. If material is not included in the article™s Creative Commons licence and your intended use is not permitted by statutory \n",
      "regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \n",
      "licence, visit \n",
      "http:// creat\n",
      " iveco\n",
      " mmons.\n",
      " org/\n",
      " licen ses/ by/4.\n",
      " 0/\n",
      "Please input the question: none\n",
      "The input has a total of 113 tokens.\n",
      "SEP token index:  2\n",
      "Number of tokens in segment A:  3\n",
      "Number of tokens in segment B:  110\n",
      "\n",
      "Question:\n",
      "None\n",
      "\n",
      "Answer:\n",
      "Images or other third party material in this article are included in the article ##™ ##s creative commons licence.\n",
      "\n",
      "\n",
      ". The Creative Commons Public Domain Dedication waiver (\n",
      "http:// creat\n",
      " iveco\n",
      " mmons.\n",
      " org/\n",
      " publi cdoma in/ zero/1.\n",
      " 0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data\n",
      "Please input the question: none\n",
      "The input has a total of 62 tokens.\n",
      "SEP token index:  2\n",
      "Number of tokens in segment A:  3\n",
      "Number of tokens in segment B:  59\n",
      "\n",
      "Question:\n",
      "None\n",
      "\n",
      "Answer:\n",
      "Creative commons public domain dedication wai ##ver.\n",
      "\n",
      "\n",
      ".\n",
      "Open Access\n",
      "BMC Health Services ResearchChange inffglycaemic control withffstructured \n",
      "diabetes self\n",
      "nagement education inffurban \n",
      "low\n",
      "source settings: multicentre randomised \n",
      "trial offfeThectiveness\n",
      "Roberta\n",
      " Lamptey\n",
      "1,2,3,19*, Mary\n",
      " Amoakohleman\n",
      "3,4, Mary\n",
      " Moffett\n",
      " Barker\n",
      "5,6, Samuel Iddi7, Michelle\n",
      " Hadjiconstantinou5,6, Melanie\n",
      " Davies\n",
      "5,6,8,9, Daniel Darko\n",
      "10,11, Irene\n",
      " Agyepong\n",
      "12, Franklyn\n",
      " Acheampong\n",
      "13, Mary\n",
      " Commey\n",
      "14, Alfred\n",
      " Yawson\n",
      "2,15, Diederick\n",
      " E\n",
      "Please input the question: none\n",
      "The input has a total of 146 tokens.\n",
      "SEP token index:  2\n",
      "Number of tokens in segment A:  3\n",
      "Number of tokens in segment B:  143\n",
      "\n",
      "Question:\n",
      "None\n",
      "\n",
      "Answer:\n",
      "[sep].\n",
      "\n",
      "\n",
      ". Grobbee\n",
      "3, George\n",
      " Obeng Adjei\n",
      "16,17and Kerstin\n",
      " Klipsteinobusch\n",
      "3,18Abstract\n",
      " Background\n",
      " In high\n",
      "source settings, structured diabetes self\n",
      "nagement education is associated with improved \n",
      "outcomes but the evidence from low\n",
      "source settings is limited and inconclusive.\n",
      "Aim\n",
      " To compare, structured diabetes self\n",
      "nagement education to usual care, in adults with type 2diabetes, in \n",
      "low\n",
      "source settings.\n",
      "Research design and methods.\n",
      "Design\n",
      " Singleind randomised parallel comparator controlled multi\n",
      "ntre trial\n",
      "Please input the question: none\n",
      "The input has a total of 113 tokens.\n",
      "SEP token index:  2\n",
      "Number of tokens in segment A:  3\n",
      "Number of tokens in segment B:  110\n",
      "\n",
      "Question:\n",
      "None\n",
      "\n",
      "Answer:\n",
      "[sep].\n",
      "\n",
      "\n",
      ".\n",
      "Adults (>\n",
      " 18years) with type 2diabetes from two hospitals in urban Ghana were randomised 1:1to usual care only, \n",
      "or usual care plus a structured diabetes self\n",
      "nagement education program. Randomisation codes were computer\n",
      "nerated, and allotment concealed in opaque numbered envelopes. The intervention effect was assessed with linear \n",
      "mixed models.\n",
      "Main outcome: Change in HbA1c after 3\n",
      "nth follow\n",
      ".\n",
      "Primary analysis involved all participants.\n",
      "Clinicaltrial\n",
      "Please input the question: What is the main outcome?\n",
      "The input has a total of 106 tokens.\n",
      "SEP token index:  7\n",
      "Number of tokens in segment A:  8\n",
      "Number of tokens in segment B:  98\n",
      "\n",
      "Question:\n",
      "What is the main outcome?\n",
      "\n",
      "Answer:\n",
      "Change in h ##ba ##1 ##c after 3 nt ##h follow.\n",
      "\n",
      "\n",
      ".gov identiTher:NCT04780425, retrospectively registered on 03/03/2021.\n",
      "Results\n",
      " Recruitment: \n",
      " 22nd until 29th January 2021.\n",
      "We randomised 206participants (69% female, median age 58\n",
      " years [IQR: 49Œ64], baseline HbA1c median 64\n",
      " mmol/mol [IQR: 45Œ88mmol/mol],7.9%[IQR: 6.4Œ10.2]). Primary outcome data was available for 79and 80participants in \n",
      "the intervention and control groups, respectively. Reasons for loss to follow\n",
      " were death (n\n",
      " ˜ 1), stroke(n\n",
      " ˜ 1) and \n",
      "unreachable or unavailable (n\n",
      " ˜ 47)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-eafee59bb35a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mqntext_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-55b7962f06cf>\u001b[0m in \u001b[0;36mqntext_func\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BERT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mquestion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please input the question: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The input has a total of {} tokens.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "qntext_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
